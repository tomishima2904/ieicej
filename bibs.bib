@inproceedings{liu-etal-2022-wax,
    title = "{WAX}: A New Dataset for Word Association e{X}planations",
    author = "Liu, Chunhua  and
      Cohn, Trevor  and
      Deyne, Simon De  and
      Frermann, Lea",
    editor = "He, Yulan  and
      Ji, Heng  and
      Li, Sujian  and
      Liu, Yang  and
      Chang, Chua-Hui",
    booktitle = "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2022",
    address = "Online only",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.aacl-main.9",
    pages = "106--120",
    abstract = "Word associations are among the most common paradigms to study the human mental lexicon. While their structure and types of associations have been well studied, surprisingly little attention has been given to the question of why participants produce the observed associations. Answering this question would not only advance understanding of human cognition, but could also aid machines in learning and representing basic commonsense knowledge. This paper introduces a large, crowd-sourced data set of English word associations with explanations, labeled with high-level relation types. We present an analysis of the provided explanations, and design several tasks to probe to what extent current pre-trained language models capture the underlying relations. Our experiments show that models struggle to capture the diversity of human associations, suggesting WAX is a rich benchmark for commonsense modeling and generation.",
}
@inproceedings{s-liu-etal-2022-wax,
    title = "{WAX}: A New Dataset for Word Association e{X}planations",
    author = "Liu, Chunhua  and
      et al.",
    year = "2022",
}

@misc{liu2019roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{s-liu2019roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
}

@article{de2019small,
  title={The “Small World of Words” English word association norms for over 12,000 cue words},
  author={De Deyne, Simon and Navarro, Danielle J and Perfors, Amy and Brysbaert, Marc and Storms, Gert},
  journal={Behavior research methods},
  volume={51},
  pages={987--1006},
  year={2019},
  publisher={Springer}
}
@article{s-de2019small,
  title={The “Small World of Words” English word association norms for over 12,000 cue words},
  author={De Deyne, Simon and et al.},
  year={2019},
}

@book{水野りか2011連想語頻度表,
  title={連想語頻度表: 3 モーラの漢字・ひらがな・カタカナ表記語},
  author={水野りか and 柳谷啓子 and 清河幸子 and 川上正浩},
  year={2011},
  publisher={Kabushiki Kaisha Nakanishiya Shuppan}
}
@book{s-水野りか2011連想語頻度表,
  author         = {水野 りか and 他},
  title          = {連想語頻度表―3 モーラの漢字・ひらがな・カタカナ表記語},
  year           = {2011}
}
